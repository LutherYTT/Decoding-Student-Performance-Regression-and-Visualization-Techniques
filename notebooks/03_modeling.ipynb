{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial p-values:\n",
      "const                          0.000000e+00\n",
      "Hours_Studied                  0.000000e+00\n",
      "Attendance                     0.000000e+00\n",
      "Parental_Involvement          2.252884e-121\n",
      "Access_to_Resources           1.045109e-123\n",
      "Extracurricular_Activities     3.309220e-22\n",
      "Sleep_Hours                    5.428518e-01\n",
      "Previous_Scores               5.852143e-120\n",
      "Motivation_Level               2.261610e-33\n",
      "Internet_Access                1.221407e-17\n",
      "Tutoring_Sessions              1.112693e-95\n",
      "Family_Income                  3.494113e-42\n",
      "Teacher_Quality                5.548306e-01\n",
      "School_Type                    9.769793e-01\n",
      "Peer_Influence                 8.338584e-14\n",
      "Physical_Activity              2.505874e-10\n",
      "Learning_Disabilities          1.156969e-20\n",
      "Parental_Education_Level       1.884156e-31\n",
      "Distance_from_Home             1.656248e-24\n",
      "Gender                         7.878864e-01\n",
      "dtype: float64\n",
      "Max p-value: 0.9770\n",
      "Dropping feature: School_Type with p-value: 0.9770\n",
      "Max p-value: 0.7882\n",
      "Dropping feature: Gender with p-value: 0.7882\n",
      "Max p-value: 0.5560\n",
      "Dropping feature: Teacher_Quality with p-value: 0.5560\n",
      "Max p-value: 0.5397\n",
      "Dropping feature: Sleep_Hours with p-value: 0.5397\n",
      "Max p-value: 0.0000\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             Exam_Score   R-squared:                       0.702\n",
      "Model:                            OLS   Adj. R-squared:                  0.701\n",
      "Method:                 Least Squares   F-statistic:                     827.9\n",
      "Date:                Fri, 16 May 2025   Prob (F-statistic):               0.00\n",
      "Time:                        15:49:07   Log-Likelihood:                -11521.\n",
      "No. Observations:                5285   AIC:                         2.307e+04\n",
      "Df Residuals:                    5269   BIC:                         2.318e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================================\n",
      "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------------\n",
      "const                         39.3910      0.312    126.281      0.000      38.780      40.003\n",
      "Hours_Studied                  0.2919      0.005     59.265      0.000       0.282       0.302\n",
      "Attendance                     0.1992      0.003     77.632      0.000       0.194       0.204\n",
      "Parental_Involvement           1.0220      0.042     24.069      0.000       0.939       1.105\n",
      "Access_to_Resources           -1.0302      0.042    -24.342      0.000      -1.113      -0.947\n",
      "Extracurricular_Activities     0.5855      0.060      9.725      0.000       0.467       0.704\n",
      "Previous_Scores                0.0492      0.002     23.991      0.000       0.045       0.053\n",
      "Motivation_Level               0.5161      0.043     12.137      0.000       0.433       0.599\n",
      "Internet_Access               -0.9440      0.110     -8.574      0.000      -1.160      -0.728\n",
      "Tutoring_Sessions              0.5073      0.024     21.203      0.000       0.460       0.554\n",
      "Family_Income                  0.5466      0.040     13.751      0.000       0.469       0.625\n",
      "Peer_Influence                -0.2487      0.033     -7.489      0.000      -0.314      -0.184\n",
      "Physical_Activity              0.1815      0.029      6.350      0.000       0.125       0.238\n",
      "Learning_Disabilities         -0.8858      0.094     -9.385      0.000      -1.071      -0.701\n",
      "Parental_Education_Level       0.4242      0.036     11.749      0.000       0.353       0.495\n",
      "Distance_from_Home            -0.4249      0.041    -10.270      0.000      -0.506      -0.344\n",
      "==============================================================================\n",
      "Omnibus:                     8369.932   Durbin-Watson:                   1.945\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          3242972.531\n",
      "Skew:                          10.433   Prob(JB):                         0.00\n",
      "Kurtosis:                     122.547   Cond. No.                     1.19e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.19e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "\n",
      "Model Evaluation Metrics:\n",
      "R-squared: 0.7570\n",
      "Mean Absolute Error (MAE): 0.5911\n",
      "Mean Squared Error (MSE): 3.4348\n",
      "Root Mean Squared Error (RMSE): 1.8533\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.api import OLS, add_constant\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Load the cleaned data\n",
    "df = pd.read_csv('../data/processed/cleaned_data.csv')\n",
    "\n",
    "# Define features and target\n",
    "X = df.drop('Exam_Score', axis=1)\n",
    "y = df['Exam_Score']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Backward elimination function\n",
    "def backward_elimination(X, y):\n",
    "    X_with_const = add_constant(X)\n",
    "    model = OLS(y, X_with_const).fit()\n",
    "    print(\"Initial p-values:\")\n",
    "    print(model.pvalues)\n",
    "    while True:\n",
    "        p_values = model.pvalues.iloc[1:]  # Exclude constant term\n",
    "        max_p_value = p_values.max()\n",
    "        print(f\"Max p-value: {max_p_value:.4f}\")\n",
    "        if max_p_value > 0.05:  # Significance level threshold\n",
    "            excluded_feature = p_values.idxmax()\n",
    "            print(f\"Dropping feature: {excluded_feature} with p-value: {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[excluded_feature])\n",
    "            model = OLS(y, add_constant(X)).fit()\n",
    "        else:\n",
    "            break\n",
    "    return model, X.columns\n",
    "\n",
    "# Fit the model using backward elimination\n",
    "final_model, selected_features = backward_elimination(X_train, y_train)\n",
    "print(final_model.summary())\n",
    "\n",
    "# Model evaluation function\n",
    "predictions = 0\n",
    "def evaluate_model(model, X_test, y_test, selected_features):\n",
    "    X_test_filtered = X_test[selected_features]\n",
    "    X_test_with_const = add_constant(X_test_filtered)\n",
    "    predictions = model.predict(X_test_with_const)\n",
    "    r_squared = r2_score(y_test, predictions)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print(\"\\nModel Evaluation Metrics:\")\n",
    "    print(f\"R-squared: {r_squared:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(final_model, X_test, y_test, selected_features)\n",
    "\n",
    "# Plot the regression line for Hours_Studied vs. Exam_Score\n",
    "\n",
    "X = df[['Attendance']]\n",
    "y = df['Exam_Score']\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "# Predict values\n",
    "y_pred = model.predict(X)\n",
    "# Calculate point density using Gaussian KDE\n",
    "xy = np.vstack([X['Attendance'], y])\n",
    "# Calculate density\n",
    "z = gaussian_kde(xy)(xy)  \n",
    "# Normalize the density values for color mapping\n",
    "z = (z - z.min()) / (z.max() - z.min())  # Normalize to [0, 1]\n",
    "# Plotting the data points with density-based color\n",
    "plt.figure(figsize=(12, 8))\n",
    "scatter = plt.scatter(X, y, c=z, s=100, edgecolor='black', alpha=0.7, cmap='viridis', label='Data Points', marker='o')\n",
    "# Plotting the regression line\n",
    "plt.plot(X, y_pred, color='tomato', linewidth=2.5, linestyle='--', label='Regression Line')\n",
    "# Adding labels and title with enhanced aesthetics\n",
    "plt.xlabel('Attendance (%)', fontsize=16)\n",
    "plt.ylabel('Exam Score', fontsize=16)\n",
    "plt.title('Regression Line with Data Points (Density Colored)', fontsize=20)\n",
    "plt.legend(fontsize=14)\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "# Show color bar for density representation\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Point Density')\n",
    "# Show plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "plt.savefig('../reports/figures/regression_line.png')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
